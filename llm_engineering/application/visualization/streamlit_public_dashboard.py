"""
ìƒì¼ë³„/ì£¼ê°„/ì›”ê°„ í™œë™ ë¦¬í¬íŠ¸ - ê³µê°œ ë°°í¬ìš© ëŒ€ì‹œë³´ë“œ

ê°œì¸ì •ë³´ ë³´í˜¸ ì •ì±…:
- ìµœê·¼ 7ì¼ ë°ì´í„°ë§Œ í‘œì‹œ
- ì¼/ìƒì‚°, í•™ìŠµ/ì„±ì¥ ì¹´í…Œê³ ë¦¬ì˜ ë©”ëª¨ë§Œ ê³µê°œ
- #ì¸ê°„ê´€ê³„ ê´€ë ¨ ìƒì„¸ ë‚´ìš© ë¹„ê³µê°œ
- LLM í”¼ë“œë°±ì€ ê³µê°œìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (v2_public)
- ì£¼ê°„/ì›”ê°„ ë¦¬í¬íŠ¸ëŠ” ì‚¬ì „ ê³„ì‚° ë©”íŠ¸ë¦­ ê¸°ë°˜ V2 Public ìŠ¤íƒ€ì¼ ì‚¬ìš©

LLM ëª¨ë¸: GPT-5 (OpenAI ìµœì‹  ëª¨ë¸)

íƒ­ êµ¬ì¡°:
- ì¼ì¼: Interactive ì‹œê°í™” + ê³µê°œìš© ì¼ì¼ í”¼ë“œë°±
- ì£¼ê°„: V2 Public (ì‚¬ì „ê³„ì‚° ë©”íŠ¸ë¦­ + ê°œì¸ì •ë³´ ë³´í˜¸)
- ì›”ê°„: V2 Public (ì£¼ê°„ V2 ê¸°ë°˜ + ê°œì¸ì •ë³´ ë³´í˜¸)
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parents[3]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import asyncio
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from loguru import logger

from llm_engineering.domain.cleaned_documents import CleanedCalendarDocument
from llm_engineering.domain.feedback_documents import (
    PublicDailyFeedbackDocument,
    PublicWeeklyFeedbackDocument,
    PublicMonthlyFeedbackDocument,
)
from llm_engineering.application.feedback.daily.generator import DailyFeedbackGenerator
from llm_engineering.application.feedback.weekly.generator import WeeklyFeedbackGenerator
from llm_engineering.application.feedback.weekly.metrics import compute_weekly_metrics
from llm_engineering.application.feedback.document_loader import DocumentLoader
from llm_engineering.application.visualization.daily_report_interactive import (
    format_duration,
    plot_agency_pie_chart_interactive,
    plot_category_distribution_interactive,
    plot_sleep_breakdown_interactive,
    plot_work_by_event_interactive,
    plot_learning_by_event_interactive,
    plot_recharge_by_event_interactive,
    plot_drain_by_event_interactive,
    plot_maintenance_by_event_interactive,
    plot_relationship_by_agency_interactive,
)
from llm_engineering.application.visualization.privacy_utils import (
    apply_public_privacy_filter,
    validate_public_data,
    get_public_summary_stats,
)
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage


# Tooltip ìŠ¤íƒ€ì¼ ì •ì˜
TOOLTIP_CSS = """
<style>
.chart-title-tooltip {
    position: relative;
    display: inline-block;
    cursor: help;
    font-size: 1.5rem;
    font-weight: 600;
    margin-bottom: 0.5rem;
}

.chart-title-tooltip .tooltiptext {
    visibility: hidden;
    width: 300px;
    background-color: #262730;
    color: #fafafa;
    text-align: left;
    padding: 10px;
    border-radius: 6px;
    border: 1px solid #464646;

    position: absolute;
    z-index: 1000;
    bottom: 125%;
    left: 50%;
    margin-left: -150px;

    opacity: 0;
    transition: opacity 0.3s;

    font-size: 0.875rem;
    font-weight: normal;
}

.chart-title-tooltip:hover .tooltiptext {
    visibility: visible;
    opacity: 1;
}

.chart-title-tooltip .tooltiptext::after {
    content: "";
    position: absolute;
    top: 100%;
    left: 50%;
    margin-left: -5px;
    border-width: 5px;
    border-style: solid;
    border-color: #464646 transparent transparent transparent;
}
</style>
"""


def show_section_title_with_tooltip(title: str, tooltip: str):
    """
    í˜¸ë²„ ì‹œ íˆ´íŒì´ ë‚˜íƒ€ë‚˜ëŠ” ì„¹ì…˜ ì œëª© í‘œì‹œ

    Args:
        title: ì„¹ì…˜ ì œëª©
        tooltip: í˜¸ë²„ ì‹œ ë‚˜íƒ€ë‚  íˆ´íŒ í…ìŠ¤íŠ¸
    """
    st.markdown(TOOLTIP_CSS, unsafe_allow_html=True)
    st.markdown(f"""
    <div class="chart-title-tooltip">
        {title}
        <span class="tooltiptext">{tooltip}</span>
    </div>
    """, unsafe_allow_html=True)


def get_weekday_korean(date_str: str) -> str:
    """
    ë‚ ì§œ ë¬¸ìì—´ì—ì„œ í•œê¸€ ìš”ì¼ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        date_str: YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´

    Returns:
        í•œê¸€ ìš”ì¼ (ì›”, í™”, ìˆ˜, ëª©, ê¸ˆ, í† , ì¼)
    """
    weekday_map = {
        0: 'ì›”', 1: 'í™”', 2: 'ìˆ˜', 3: 'ëª©',
        4: 'ê¸ˆ', 5: 'í† ', 6: 'ì¼'
    }
    date_obj = pd.to_datetime(date_str)
    return weekday_map[date_obj.weekday()]


# ê³µê°œìš© ëŒ€ì‹œë³´ë“œ ë‚ ì§œ ë²”ìœ„ ì œí•œ (ìƒ˜í”Œ ê¸°ê°„)
PUBLIC_START_DATE = datetime(2025, 11, 3).date()
PUBLIC_END_DATE = datetime(2025, 11, 27).date()


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¼ë³„ í™œë™ ë¦¬í¬íŠ¸ (ê³µê°œ)",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded",
)


def load_daily_data(date_str: str) -> pd.DataFrame:
    """
    íŠ¹ì • ë‚ ì§œì˜ CleanedCalendarDocumentë¥¼ ë¡œë“œí•˜ì—¬ DataFrameìœ¼ë¡œ ë³€í™˜.
    ê³µê°œ ë°°í¬ìš©: í”„ë¼ì´ë²„ì‹œ í•„í„° ìë™ ì ìš©
    """
    try:
        docs = list(CleanedCalendarDocument.bulk_find(ref_date=date_str))

        if not docs:
            return None

        data = []
        for doc in docs:
            metadata = doc.metadata
            data.append({
                'original_id': str(doc.original_id),
                'start_datetime': pd.to_datetime(metadata.get('start_datetime')),
                'end_datetime': pd.to_datetime(metadata.get('end_datetime')),
                'duration_minutes': metadata.get('duration_minutes', 0),
                'category_name': metadata.get('category_name'),
                'calendar_name': metadata.get('category_name'),
                'event_name': metadata.get('event_name'),
                'notes': metadata.get('notes', ''),
                'sub_category': metadata.get('sub_category', ''),
                'learning_method': metadata.get('learning_method'),
                'learning_target': metadata.get('learning_target'),
                'work_tags': metadata.get('work_tags', []),
                'exercise_type': metadata.get('exercise_type'),
                'is_risky_recharger': metadata.get('is_risky_recharger', False),
                'has_relationship_tag': metadata.get('has_relationship_tag', False),
                'has_emotion_event': metadata.get('has_emotion_event', False),
            })

        df = pd.DataFrame(data)
        df = df.sort_values('start_datetime').reset_index(drop=True)

        # âœ… ê³µê°œ ë°°í¬ìš© í”„ë¼ì´ë²„ì‹œ í•„í„° ì ìš©
        df_filtered = apply_public_privacy_filter(
            df,
            days=7,
            ref_date=date_str,
            mask_notes=True,
            anonymize_names=True
        )

        return df_filtered
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


def show_statistics(df: pd.DataFrame, target_date: str, is_weekly: bool = False, start_date: str = None, end_date: str = None):
    """ì „ì²´ í†µê³„ í‘œì‹œ (ì¼ì¼/ì£¼ê°„ ëª¨ë“œ ì§€ì›)"""
    if is_weekly and start_date and end_date:
        st.subheader(f"ğŸ“Š ì£¼ê°„ í†µê³„: {start_date} ~ {end_date}")
    else:
        weekday = get_weekday_korean(target_date)
        st.subheader(f"ğŸ“Š {target_date} ({weekday}) ì „ì²´ í†µê³„")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        # duration_minutes ì»¬ëŸ¼ ì²´í¬
        if 'duration_minutes' in df.columns:
            st.metric("ì´ ê¸°ë¡ ì‹œê°„", format_duration(df['duration_minutes'].sum()))
        elif 'duration_hours' in df.columns:
            total_hours = df['duration_hours'].sum()
            st.metric("ì´ ê¸°ë¡ ì‹œê°„", f"{total_hours:.1f}h")
        elif 'duration' in df.columns:
            st.metric("ì´ ê¸°ë¡ ì‹œê°„", format_duration(df['duration'].sum()))
        else:
            st.metric("ì´ ê¸°ë¡ ì‹œê°„", "N/A")

    with col2:
        st.metric("ì´ í™œë™ ìˆ˜", f"{len(df)}ê°œ")

    with col3:
        # ê³µê°œìš©ì´ë¯€ë¡œ ì¸ê°„ê´€ê³„/ì¦‰ì‹œë§Œì¡± ë©”íŠ¸ë¦­ì€ ì¡°ê±´ë¶€ í‘œì‹œ
        if 'has_relationship_tag' in df.columns:
            st.metric("#ì¸ê°„ê´€ê³„", f"{df['has_relationship_tag'].sum()}ê°œ")
        elif 'duration_minutes' in df.columns:
            avg_duration = df['duration_minutes'].mean()
            st.metric("í‰ê·  í™œë™ ì‹œê°„", format_duration(avg_duration) if not pd.isna(avg_duration) else "N/A")
        else:
            st.metric("í‰ê·  í™œë™ ì‹œê°„", "N/A")

    with col4:
        if 'is_risky_recharger' in df.columns:
            st.metric("#ì¦‰ì‹œë§Œì¡±", f"{df['is_risky_recharger'].sum()}ê°œ")
        elif 'category' in df.columns:
            st.metric("í™œë™ ìœ í˜•", f"{df['category'].nunique()}ê°œ")
        else:
            st.metric("í™œë™ ìœ í˜•", "N/A")


def show_agency_pie_chart(df: pd.DataFrame):
    """Agency íŒŒì´ì°¨íŠ¸ í‘œì‹œ (Interactive)"""
    show_section_title_with_tooltip(
        "ğŸ¯ Agency íŒŒì´ì°¨íŠ¸",
        "ğŸ’¡ Tip: í˜¸ë²„í•˜ë©´ ì‹¤ì œ ì˜ì—­ë³„ í•©ê³„ ì‹œê°„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    )

    fig = plot_agency_pie_chart_interactive(df, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  Agency ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


def show_category_distribution(df: pd.DataFrame):
    """ì¹´í…Œê³ ë¦¬ë³„ ì‹œê°„ ë¶„í¬ í‘œì‹œ (Interactive)"""
    show_section_title_with_tooltip(
        "ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ì‹œê°„ ë¶„í¬",
        "ğŸ’¡ Tip: ë°”ë¥¼ í˜¸ë²„í•˜ë©´ í•˜ë£¨ ê¸°ì¤€ í¼ì„¼í‹°ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ê³¼ë„í•˜ê²Œ íšŒë³µì— ë§ì´ ì‚¬ìš©ë ê²½ìš° ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤"
    )

    fig = plot_category_distribution_interactive(df, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  ì¹´í…Œê³ ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


def show_sleep_breakdown(df: pd.DataFrame):
    """ìˆ˜ë©´ ìƒì„¸ ë¶„ì„ í‘œì‹œ (Interactive)"""
    show_section_title_with_tooltip(
        "ğŸ˜´ ìˆ˜ë©´ ìƒì„¸ ë¶„ì„",
        "ğŸ’¡ Tip: ë°”ë¥¼ í˜¸ë²„í•˜ë©´ ê° ìˆ˜ë©´ ì´ë²¤íŠ¸ì˜ ë©”ëª¨ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    )

    fig = plot_sleep_breakdown_interactive(df, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  ìˆ˜ë©´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


def show_five_areas_analysis(df: pd.DataFrame):
    """5ê°œ ì˜ì—­ ìƒì„¸ ë¶„ì„ (Interactive Plotly)"""


    # 1. ì¼/ìƒì‚°
    show_section_title_with_tooltip(
        "ğŸ’¼ ì¼/ìƒì‚°",
        "ğŸ’¡ Tip: ë°”ë¥¼ í˜¸ë²„í•˜ë©´ ë©”ëª¨ì™€ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    )
    fig = plot_work_by_event_interactive(df, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  ì¼/ìƒì‚° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # 2. í•™ìŠµ/ì„±ì¥
    show_section_title_with_tooltip(
        "ğŸ“š í•™ìŠµ/ì„±ì¥ ",
        "ğŸ’¡ Tip: ë°”ë¥¼ í˜¸ë²„í•˜ë©´ ë©”ëª¨ì™€ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    )
    fig = plot_learning_by_event_interactive(df, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  í•™ìŠµ/ì„±ì¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # 3. ì¬ì¶©ì „ í™œë™
    show_section_title_with_tooltip(
        "ğŸŒ´ íœ´ì‹/íšŒë³µ ",
        "ğŸ’¡ Tip: ë°”ë¥¼ í˜¸ë²„í•˜ë©´ ë©”ëª¨ì™€ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    )
    fig = plot_recharge_by_event_interactive(df, top_n=15, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  ì¬ì¶©ì „ í™œë™ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # 4. Drain
    show_section_title_with_tooltip(
        "âš ï¸ Drain",
        "ğŸ’¡ Tip: ë°”ë¥¼ í˜¸ë²„í•˜ë©´ ë©”ëª¨ì™€ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    )
    fig = plot_drain_by_event_interactive(df, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  Drain ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # 5. ì¼ìƒ ê´€ë¦¬
   
    show_section_title_with_tooltip(
        "ğŸ  ìœ ì§€/ì •ë¦¬",
        "ğŸ’¡ Tip: ë°”ë¥¼ í˜¸ë²„í•˜ë©´ ë©”ëª¨ì™€ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    )
    fig = plot_maintenance_by_event_interactive(df, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  ìœ ì§€/ì •ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # 6. #ì¸ê°„ê´€ê³„ íƒœê·¸ - Agencyë³„
    show_section_title_with_tooltip(
        "ğŸ‘¥ ì¸ê°„ê´€ê³„ - Agencyë³„ ë¶„í¬",
        "ğŸ’¡ Tip: ë°”ë¥¼ í˜¸ë²„í•˜ë©´ ë©”ëª¨ì™€ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
    )
    fig = plot_relationship_by_agency_interactive(df, show_title=False)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("âš ï¸  #ì¸ê°„ê´€ê³„ íƒœê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")




def load_or_generate_feedback(date_str: str) -> tuple[str, bool]:
    """
    ê³µê°œìš© ì¼ì¼ í”¼ë“œë°±ì„ ë¡œë“œí•˜ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤.

    ê³µê°œìš© ëŒ€ì‹œë³´ë“œ ì „ìš© í•¨ìˆ˜:
    - prompt_style: "public" ê³ ì •
    - ë³„ë„ ì»¬ë ‰ì…˜(public_daily_feedback) ì‚¬ìš©
    - ê°œì¸ìš© í”¼ë“œë°±ê³¼ ì™„ì „ ë¶„ë¦¬

    Args:
        date_str: ë‚ ì§œ (YYYY-MM-DD)

    Returns:
        (í”¼ë“œë°± ë‚´ìš©, ìƒˆë¡œ ìƒì„± ì—¬ë¶€)
    """
    # 1. ê³µê°œìš© ì»¬ë ‰ì…˜ì—ì„œ ê¸°ì¡´ í”¼ë“œë°± í™•ì¸
    existing_feedback = PublicDailyFeedbackDocument.find(
        target_date=date_str
    )

    if existing_feedback:
        return existing_feedback.content, False

    # 2. ìƒˆë¡œ ìƒì„± (public í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
    try:
        generator = DailyFeedbackGenerator(
            model_id="gpt-5",  # GPT-5ë¥¼ ê¸°ë³¸ ëª¨ë¸ë¡œ ì‚¬ìš©
            temperature=1.0,  # GPT-5ëŠ” ê¸°ë³¸ê°’(1.0)ë§Œ ì§€ì›
            prompt_style="public"  # ê³µê°œìš© í”„ë¡¬í”„íŠ¸ ê³ ì •
        )

        # í”¼ë“œë°± ìƒì„± (ê°œì¸ìš© DBì— ì €ì¥í•˜ì§€ ì•ŠìŒ)
        feedback_content = generator.generate(
            target_date=date_str,
            include_previous=True,
            include_next=True,
            save_to_db=False  # ê°œì¸ìš© DBì— ì €ì¥ ì•ˆ í•¨
        )

        # 3. ê³µê°œìš© ì»¬ë ‰ì…˜ì— ì €ì¥
        public_feedback = PublicDailyFeedbackDocument(
            target_date=date_str,
            content=feedback_content,
            model_used=generator.model_id,  # model_idê°€ ì˜¬ë°”ë¥¸ ì†ì„±ëª…
            temperature=generator.temperature,
            prompt_style="public",
            include_previous=True,
            include_next=True,
        )
        public_feedback.save()

        return feedback_content, True
    except Exception as e:
        return f"âŒ í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", False


def show_llm_feedback(date_str: str):
    """ê³µê°œìš© ì¼ì¼ í”¼ë“œë°± ì˜ì—­ (GPT-5, public í”„ë¡¬í”„íŠ¸ ê³ ì •)"""
    st.caption("ğŸ¤– Powered by GPT-5 | ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ì¼ë°˜í™”ëœ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")

    # í”¼ë“œë°± ìƒì„±/ë¡œë“œ ë²„íŠ¼
    col1, col2 = st.columns([1, 1])

    with col1:
        load_button = st.button("ğŸ“¥ í”¼ë“œë°± ë¶ˆëŸ¬ì˜¤ê¸°", type="primary", use_container_width=True)

    with col2:
        regenerate_button = st.button("ğŸ”„ ìƒˆë¡œ ìƒì„±", use_container_width=True)

    st.markdown("---")

    # í”¼ë“œë°± í‘œì‹œ ì˜ì—­
    if load_button or regenerate_button:
        with st.spinner("í”¼ë“œë°± ë¡œë”© ì¤‘..." if load_button else "í”¼ë“œë°± ìƒì„± ì¤‘..."):
            if regenerate_button:
                # ê°•ì œ ì¬ìƒì„±: ê¸°ì¡´ ê³µê°œìš© í”¼ë“œë°± ì‚­ì œ í›„ ìƒì„±
                try:
                    existing = PublicDailyFeedbackDocument.find(
                        target_date=date_str
                    )
                    if existing:
                        # MongoDBì—ì„œ ì‚­ì œí•˜ëŠ” ë©”ì„œë“œê°€ ìˆë‹¤ë©´ ì‚¬ìš©
                        pass  # ì¼ë‹¨ ë®ì–´ì“°ê¸°ë¡œ ì²˜ë¦¬
                except:
                    pass

            feedback, is_new = load_or_generate_feedback(date_str)

            if is_new:
                st.success("âœ… ìƒˆë¡œìš´ í”¼ë“œë°±ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                st.info("ğŸ“¥ ì €ì¥ëœ í”¼ë“œë°±ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

            st.markdown("---")
            st.markdown("### ğŸ“‹ ì¼ì¼ í”¼ë“œë°±")
            st.markdown(feedback)
    else:
        # ì´ˆê¸° ìƒíƒœ ë˜ëŠ” ìë™ ë¡œë“œ
        st.info("""
            **ğŸŒ GPT-5 ê¸°ë°˜ ì¼ì¼ í”¼ë“œë°±**

        **ë¶„ì„ ë²”ìœ„**:
        - âš–ï¸ 4ê°€ì§€ ëª¨ë“œ(ìƒì‚°, í•™ìŠµ, ìœ ì§€, íšŒë³µ) ê¸°ë°˜ ì‹œê°„ ê· í˜• ë¶„ì„
        - ğŸŒ™ ë£¨í‹´ ë¶•ê´´ ì›ì¸ ì§„ë‹¨
        - ğŸ“‰ ì¶©ë™ì  ì—ë„ˆì§€ ì†Œëª¨ íŒ¨í„´ ì‹ë³„
        - ğŸš¨ ë°ì´í„° ê¸°ë°˜ ëŒ€ì‘ ì œì•ˆ

        **í”„ë¼ì´ë²„ì‹œ ë³´í˜¸**:
        - ê°œì¸ ì‹ë³„ ì •ë³´ ì œì™¸
        - ë¯¼ê°í•œ ë©”ëª¨ ë‚´ìš© ë¹„ê³µê°œ
        - ì¸ê°„ê´€ê³„ ìƒì„¸ ë‚´ìš© ë¹„ê³µê°œ

        **ëª¨ë¸**: GPT-5 (OpenAI ìµœì‹  ëª¨ë¸)

        ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ í”¼ë“œë°±ì„ í™•ì¸í•˜ì„¸ìš”.
        """)

        # ìë™ ë¡œë“œ ì˜µì…˜
        if st.checkbox("í˜ì´ì§€ ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ í”¼ë“œë°± ë¶ˆëŸ¬ì˜¤ê¸°"):
            feedback, is_new = load_or_generate_feedback(date_str)
            st.markdown("---")
            st.markdown("### ğŸ“‹ ê³µê°œìš© ì¼ì¼ í”¼ë“œë°±")
            st.markdown(feedback)


# ============================================================================
# ì£¼ê°„/ì›”ê°„ V2 Public ìƒì„± í—¬í¼ í•¨ìˆ˜ë“¤
# ============================================================================

async def _generate_weekly_v2_report_async(
    week_num: int,
    week_start: str,
    week_end: str,
    week_df: pd.DataFrame,
    model_id: str,
    temperature: float,
) -> str:
    """
    ë‹¨ì¼ ì£¼ê°„ V2 Public ë¦¬í¬íŠ¸ë¥¼ ë¹„ë™ê¸°ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        week_num: ì£¼ ë²ˆí˜¸
        week_start: ì£¼ ì‹œì‘ ë‚ ì§œ
        week_end: ì£¼ ì¢…ë£Œ ë‚ ì§œ
        week_df: í•´ë‹¹ ì£¼ì˜ ë°ì´í„° DataFrame
        model_id: ëª¨ë¸ ID
        temperature: ì˜¨ë„

    Returns:
        ì£¼ê°„ V2 Public ë¦¬í¬íŠ¸ ë¬¸ìì—´ (JSON ì œê±°ë¨)
    """
    if week_df.empty:
        return f"### Week {week_num}: {week_start} ~ {week_end}\n\në°ì´í„° ì—†ìŒ\n\n---"

    logger.info(f"Generating v2_public report for Week {week_num}: {week_start} ~ {week_end}")

    # ì£¼ê°„ ë©”íŠ¸ë¦­ ê³„ì‚°
    week_metrics = compute_weekly_metrics(week_df, week_start, week_end)

    # ì£¼ê°„ V2 Public ë¦¬í¬íŠ¸ ìƒì„±
    generator = WeeklyFeedbackGenerator(
        model_id=model_id,
        temperature=temperature,
        prompt_style="v2_public",  # í•­ìƒ v2_public ì‚¬ìš©
    )

    # ì£¼ê°„ ë°ì´í„° ë¡œë“œ
    weekly_docs = DocumentLoader.load_by_date_range(
        start_date=week_start,
        end_date=week_end,
        sources=["calendar", "notion", "naver_blog"],
        include_weekly_reports=False,
    )

    # ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
    context = generator._format_v2_context(
        week_start, week_end, weekly_docs, [], week_metrics
    )

    # LLM ë¹„ë™ê¸° í˜¸ì¶œ
    response = await generator.llm.ainvoke([HumanMessage(content=context)])
    week_feedback = response.content

    # JSON ë¶€ë¶„ ì œê±°
    week_feedback_clean = WeeklyFeedbackGenerator.remove_json_section(week_feedback)

    logger.info(f"Week {week_num} v2_public report generated ({len(week_feedback_clean)} chars)")

    return f"### Week {week_num}: {week_start} ~ {week_end}\n\n{week_feedback_clean}\n\n---"


async def _generate_all_weekly_v2_reports_async(
    weeks: list[tuple[str, str]],
    df: pd.DataFrame,
    model_id: str,
    temperature: float,
) -> list[str]:
    """
    ëª¨ë“  ì£¼ê°„ V2 Public ë¦¬í¬íŠ¸ë¥¼ ë³‘ë ¬ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        weeks: [(week_start, week_end), ...] ë¦¬ìŠ¤íŠ¸
        df: ì›”ê°„ ë°ì´í„° DataFrame
        model_id: ëª¨ë¸ ID
        temperature: ì˜¨ë„

    Returns:
        ì£¼ê°„ V2 Public ë¦¬í¬íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    tasks = []
    for week_num, (week_start, week_end) in enumerate(weeks, 1):
        # í•´ë‹¹ ì£¼ì˜ ë°ì´í„° í•„í„°ë§
        week_df = df[
            (df['ref_date'] >= week_start) &
            (df['ref_date'] <= week_end)
        ].copy()

        task = _generate_weekly_v2_report_async(
            week_num, week_start, week_end, week_df, model_id, temperature
        )
        tasks.append(task)

    logger.info(f"Starting parallel generation of {len(tasks)} weekly v2_public reports")
    reports = await asyncio.gather(*tasks)
    logger.info(f"Completed parallel generation of {len(reports)} weekly v2_public reports")

    return reports


def _generate_monthly_from_weekly_v2(
    year: int,
    month: int,
    model_id: str,
    temperature: float,
    df: pd.DataFrame,
) -> str:
    """
    ì£¼ê°„ V2 Public ë¦¬í¬íŠ¸ë¥¼ ë³‘ë ¬ë¡œ ìƒì„±í•œ í›„ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›”ê°„ V2 Public ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        year: ì—°ë„
        month: ì›”
        model_id: ëª¨ë¸ ID
        temperature: ì˜¨ë„
        df: ì›”ê°„ ë°ì´í„° DataFrame

    Returns:
        ì›”ê°„ V2 Public í”¼ë“œë°± ë¬¸ìì—´
    """
    # 1. ì›”ì„ ì£¼ë³„ë¡œ ë¶„í• 
    start_date = datetime(year, month, 1)
    if month == 12:
        end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
    else:
        end_date = datetime(year, month + 1, 1) - timedelta(days=1)

    weeks = []
    current = start_date
    while current <= end_date:
        week_start = current - timedelta(days=current.weekday())
        week_end = week_start + timedelta(days=6)

        if week_start < start_date:
            week_start = start_date
        if week_end > end_date:
            week_end = end_date

        weeks.append((week_start.strftime("%Y-%m-%d"), week_end.strftime("%Y-%m-%d")))
        current = week_end + timedelta(days=1)

    # 2. ê° ì£¼ë³„ V2 Public ë¦¬í¬íŠ¸ ë³‘ë ¬ ìƒì„±
    weekly_v2_reports = asyncio.run(
        _generate_all_weekly_v2_reports_async(weeks, df, model_id, temperature)
    )

    # 3. ì£¼ê°„ V2 Public ë¦¬í¬íŠ¸ë“¤ì„ ì¢…í•©í•˜ì—¬ ì›”ê°„ í”¼ë“œë°± ìƒì„±
    monthly_prompt = f"""ë‹¹ì‹ ì€ **ê³µê°œ ë°°í¬ìš©** ì›”ê°„ í–‰ë™ íŒ¨í„´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**PRIVACY PROTECTION POLICY:**

1. **Personal Information Protection:**
   - âŒ NO people names, places, organization names
   - âŒ NO relationship details beyond time allocation
   - âŒ NO sensitive personal context

2. **Content Disclosure Rules:**
   - âœ… PUBLIC: Work/production, Learning/growth patterns
   - âš ï¸ LIMITED: Recharge, Maintenance - **time only**
   - âŒ PRIVATE: Relationship specifics, personal contexts

3. **Analysis Focus:**
   - Generic behavioral patterns and trends
   - Anonymized triggers and contexts
   - Privacy-safe recommendations

ì•„ë˜ëŠ” {year}ë…„ {month}ì›”ì˜ ì£¼ë³„ V2 ë¦¬í¬íŠ¸ë“¤ì…ë‹ˆë‹¤.
ê° ì£¼ê°„ ë¦¬í¬íŠ¸ëŠ” ì´ë¯¸ ì‚¬ì „ ê³„ì‚°ëœ ë©”íŠ¸ë¦­ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, íŒ¨í„´ ë¶„ì„ê³¼ ëŒ€í‘œ íƒœê·¸ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
**ëª¨ë“  ë¦¬í¬íŠ¸ëŠ” ê°œì¸ì •ë³´ ë³´í˜¸ ì •ì±…ì„ ë”°ë¼ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.**

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì´ ì£¼ê°„ ë¦¬í¬íŠ¸ë“¤ì„ ì¢…í•©í•˜ì—¬ **ì›”ê°„ íŠ¸ë Œë“œ**, **ë°˜ë³µ íŒ¨í„´**, **ì¥ê¸°ì  í†µì°°**ì„ ì œê³µí•˜ë˜,
**ê°œì¸ì •ë³´ë¥¼ ì² ì €íˆ ë³´í˜¸**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ì£¼ê°„ ë¦¬í¬íŠ¸ë“¤

{"".join(weekly_v2_reports)}

## ì¶œë ¥ í˜•ì‹ (Privacy-Protected)

ë‹¤ìŒ êµ¬ì¡°ë¡œ ì›”ê°„ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”:

## ì›”ê°„ í”¼ë“œë°± ({year}ë…„ {month}ì›”)

[ì´ë²ˆ ë‹¬ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ - ê°œì¸ì •ë³´ ì œì™¸]

---

### ğŸ“Š ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„

**ì£¼ë³„ ì¶”ì´**:
- Week 1: [ì¼ë°˜í™”ëœ í•µì‹¬ íŒ¨í„´]
- Week 2: [ì¼ë°˜í™”ëœ í•µì‹¬ íŒ¨í„´]
- Week 3: [ì¼ë°˜í™”ëœ í•µì‹¬ íŒ¨í„´]
- Week 4: [ì¼ë°˜í™”ëœ í•µì‹¬ íŒ¨í„´]

**ì „ì²´ íŠ¸ë Œë“œ**: [ê°œì„ /ì•ˆì •/í•˜ë½ ë“±, êµ¬ì²´ì ì´ë˜ ê°œì¸ ë§¥ë½ ì œì™¸]

---

### ğŸ”„ ë°˜ë³µ íŒ¨í„´ ì‹ë³„

**ê¸ì •ì  íŒ¨í„´ (ì§€ì†í•´ì•¼ í•  ê²ƒ)**:
[ì—¬ëŸ¬ ì£¼ì— ê±¸ì³ ë°˜ë³µëœ ì¼ë°˜í™”ëœ ê¸ì •ì  íŒ¨í„´ 2-3ê°œ]

**ë¶€ì •ì  íŒ¨í„´ (ê°œì„ ì´ í•„ìš”í•œ ê²ƒ)**:
[ì—¬ëŸ¬ ì£¼ì— ê±¸ì³ ë°˜ë³µëœ ì¼ë°˜í™”ëœ ë¶€ì •ì  íŒ¨í„´ 2-3ê°œ]

---

### ğŸ¯ ì´ë²ˆ ë‹¬ ì£¼ìš” ì„±ê³¼

[ì›”ê°„ ê´€ì ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì„±ê³¼ 3-4ê°œ, ì¼ë°˜í™”ëœ ì„¤ëª…]

---

### âš ï¸ ì§€ì†ì  ë¬¸ì œ

[ë§¤ì£¼ ë°˜ë³µë˜ê±°ë‚˜ í•´ê²°ë˜ì§€ ì•Šì€ í–‰ë™ ë¬¸ì œë“¤, ê°œì¸ ë§¥ë½ ì œì™¸]

---

### ğŸ’¡ ë‹¤ìŒ ë‹¬ ê°œì„  ì „ëµ

[ì´ë²ˆ ë‹¬ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì²´ì ì´ë˜ ì¼ë°˜í™”ëœ ì „ëµ 3ê°œ]

---

## PRIVACY RULES

- **Remove ALL personal identifiers** (names, places, organizations)
- **Anonymize all contexts** (use generic terms like "ì§€ì¸", "ëª¨ì„")
- **Time-only for sensitive categories** (relationships, personal activities)
- **Focus on behavioral patterns**, not personal stories
- **Ensure report is safe for public distribution**

**í†¤**: ì¥ê¸°ì  ê´€ì , íŒ¨í„´ ì¤‘ì‹¬, ì „ëµì , ê· í˜•ì , **ê³µê°œ ê°€ëŠ¥**
"""

    # LLM í˜¸ì¶œ
    from llm_engineering.settings import Settings
    settings = Settings.load_settings()

    llm = ChatOpenAI(
        model=model_id,
        temperature=temperature,
        openai_api_key=settings.OPENAI_API_KEY
    )
    response = llm.invoke([HumanMessage(content=monthly_prompt)])

    return response.content


def load_or_generate_weekly_feedback(
    start_date: str,
    end_date: str,
    df: pd.DataFrame
) -> tuple[str, bool, dict]:
    """
    ê³µê°œìš© ì£¼ê°„ í”¼ë“œë°±ì„ ë¡œë“œí•˜ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        start_date: ì£¼ ì‹œì‘ì¼ (YYYY-MM-DD)
        end_date: ì£¼ ì¢…ë£Œì¼ (YYYY-MM-DD)
        df: ì£¼ê°„ ë°ì´í„° DataFrame

    Returns:
        (í”¼ë“œë°± ë‚´ìš©, ìƒˆë¡œ ìƒì„± ì—¬ë¶€, ë©”íŠ¸ë¦­)
    """
    # 1. ê³µê°œìš© ì»¬ë ‰ì…˜ì—ì„œ ê¸°ì¡´ í”¼ë“œë°± í™•ì¸
    existing_feedback = PublicWeeklyFeedbackDocument.find(
        target_date=start_date,
        end_date=end_date
    )

    if existing_feedback:
        metrics = existing_feedback.precomputed_metrics or {}
        return existing_feedback.content, False, metrics

    # 2. ìƒˆë¡œ ìƒì„± (v2_public í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
    try:
        # ì£¼ê°„ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = compute_weekly_metrics(df, start_date, end_date)

        # V2 Public ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±
        generator = WeeklyFeedbackGenerator(
            model_id="gpt-5",
            temperature=1.0,  # GPT-5ëŠ” temperature=1.0ë§Œ ì§€ì›
            prompt_style="v2_public"
        )

        feedback = generator.generate(
            start_date=start_date,
            end_date=end_date,
            precomputed_metrics=metrics,
        )

        # JSON ì œê±°
        feedback_clean = WeeklyFeedbackGenerator.remove_json_section(feedback)

        # 3. ê³µê°œìš© ì»¬ë ‰ì…˜ì— ì €ì¥
        public_feedback = PublicWeeklyFeedbackDocument(
            target_date=start_date,
            end_date=end_date,
            content=feedback_clean,
            model_used=generator.model_id,
            temperature=generator.temperature,
            prompt_style="v2_public",
            precomputed_metrics=metrics,
        )
        public_feedback.save()

        return feedback_clean, True, metrics
    except Exception as e:
        logger.error(f"Weekly feedback generation error: {e}", exc_info=True)
        return f"âŒ í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", False, {}


def load_or_generate_monthly_feedback(
    year: int,
    month: int,
    df: pd.DataFrame
) -> tuple[str, bool]:
    """
    ê³µê°œìš© ì›”ê°„ í”¼ë“œë°±ì„ ë¡œë“œí•˜ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        year: ì—°ë„
        month: ì›”
        df: ì›”ê°„ ë°ì´í„° DataFrame

    Returns:
        (í”¼ë“œë°± ë‚´ìš©, ìƒˆë¡œ ìƒì„± ì—¬ë¶€)
    """
    # 1. ê³µê°œìš© ì»¬ë ‰ì…˜ì—ì„œ ê¸°ì¡´ í”¼ë“œë°± í™•ì¸
    existing_feedback = PublicMonthlyFeedbackDocument.find(
        year=year,
        month=month
    )

    if existing_feedback:
        return existing_feedback.content, False

    # 2. ìƒˆë¡œ ìƒì„± (v2_public í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
    try:
        # V2 Public ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±
        feedback = _generate_monthly_from_weekly_v2(
            year=year,
            month=month,
            model_id="gpt-5",
            temperature=1.0,  # GPT-5ëŠ” temperature=1.0ë§Œ ì§€ì›
            df=df,
        )

        # 3. ê³µê°œìš© ì»¬ë ‰ì…˜ì— ì €ì¥
        public_feedback = PublicMonthlyFeedbackDocument(
            target_date=f"{year}-{month:02d}",
            year=year,
            month=month,
            content=feedback,
            model_used="gpt-5",
            temperature=1.0,
            prompt_style="v2_public",
        )
        public_feedback.save()

        return feedback, True
    except Exception as e:
        logger.error(f"Monthly feedback generation error: {e}", exc_info=True)
        return f"âŒ í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", False


def load_weekly_data(start_date: str, end_date: str) -> pd.DataFrame:
    """
    ì£¼ê°„ ë°ì´í„° ë¡œë“œ.

    Note: ê°œì¸ì •ë³´ ë³´í˜¸ëŠ” V2 Public í”„ë¡¬í”„íŠ¸ì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ
    ë³„ë„ì˜ privacy í•„í„°ë¥¼ ì ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    try:
        # ë‚ ì§œ ë²”ìœ„ ë‚´ ëª¨ë“  ë¬¸ì„œ ìˆ˜ì§‘
        all_docs = []
        current_date = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")

        while current_date <= end_dt:
            date_str = current_date.strftime("%Y-%m-%d")
            docs = list(CleanedCalendarDocument.bulk_find(ref_date=date_str))
            all_docs.extend(docs)
            current_date += timedelta(days=1)

        if not all_docs:
            return None

        # metadataì—ì„œ í•„ë“œ ì¶”ì¶œ
        data = []
        for doc in all_docs:
            metadata = doc.metadata
            data.append({
                'original_id': str(doc.original_id),
                'ref_date': doc.ref_date,
                'start_datetime': pd.to_datetime(metadata.get('start_datetime')),
                'end_datetime': pd.to_datetime(metadata.get('end_datetime')),
                'duration_minutes': metadata.get('duration_minutes', 0),
                'category': metadata.get('category_name'),
                'category_name': metadata.get('category_name'),
                'calendar_name': metadata.get('category_name'),
                'event_name': metadata.get('event_name'),
                'notes': metadata.get('notes', ''),
                'sub_category': metadata.get('sub_category', ''),
                'learning_method': metadata.get('learning_method'),
                'learning_target': metadata.get('learning_target'),
                'work_tags': metadata.get('work_tags', []),
                'exercise_type': metadata.get('exercise_type'),
                'agency_mode': metadata.get('agency_mode'),
                'is_risky_recharger': metadata.get('is_risky_recharger', False),
                'has_relationship_tag': metadata.get('has_relationship_tag', False),
                'has_emotion_event': metadata.get('has_emotion_event', False),
            })

        df = pd.DataFrame(data)
        df = df.sort_values('start_datetime').reset_index(drop=True)

        return df
    except Exception as e:
        st.error(f"ì£¼ê°„ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


def load_monthly_data(year: int, month: int) -> pd.DataFrame:
    """ì›”ê°„ ë°ì´í„° ë¡œë“œ"""
    try:
        # ì›”ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ê³„ì‚°
        start_date = datetime(year, month, 1)
        if month == 12:
            end_date = datetime(year + 1, 1, 1) - timedelta(days=1)
        else:
            end_date = datetime(year, month + 1, 1) - timedelta(days=1)

        start_str = start_date.strftime("%Y-%m-%d")
        end_str = end_date.strftime("%Y-%m-%d")

        # ë‚ ì§œ ë²”ìœ„ ë‚´ ëª¨ë“  ë¬¸ì„œ ìˆ˜ì§‘
        all_docs = []
        current_date = start_date

        while current_date <= end_date:
            date_str = current_date.strftime("%Y-%m-%d")
            docs = list(CleanedCalendarDocument.bulk_find(ref_date=date_str))
            all_docs.extend(docs)
            current_date += timedelta(days=1)

        if not all_docs:
            return None

        # metadataì—ì„œ í•„ë“œ ì¶”ì¶œ
        data = []
        for doc in all_docs:
            metadata = doc.metadata
            data.append({
                'original_id': str(doc.original_id),
                'ref_date': doc.ref_date,
                'start_datetime': pd.to_datetime(metadata.get('start_datetime')),
                'end_datetime': pd.to_datetime(metadata.get('end_datetime')),
                'duration_minutes': metadata.get('duration_minutes', 0),
                'category': metadata.get('category_name'),
                'category_name': metadata.get('category_name'),
                'calendar_name': metadata.get('category_name'),
                'event_name': metadata.get('event_name'),
                'notes': metadata.get('notes', ''),
                'sub_category': metadata.get('sub_category', ''),
                'learning_method': metadata.get('learning_method'),
                'learning_target': metadata.get('learning_target'),
                'work_tags': metadata.get('work_tags', []),
                'exercise_type': metadata.get('exercise_type'),
                'agency_mode': metadata.get('agency_mode'),
                'is_risky_recharger': metadata.get('is_risky_recharger', False),
                'has_relationship_tag': metadata.get('has_relationship_tag', False),
                'has_emotion_event': metadata.get('has_emotion_event', False),
            })

        df = pd.DataFrame(data)
        df = df.sort_values('start_datetime').reset_index(drop=True)

        return df
    except Exception as e:
        st.error(f"ì›”ê°„ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


def main():
    # íƒ­ ìƒì„± 
    tab_daily, tab_weekly, tab_monthly = st.tabs(["ğŸ“… ì¼ì¼", "ğŸ“ˆ ì£¼ê°„", "ğŸ“Š ì›”ê°„"])

    # ì‚¬ì´ë“œë°” ê³µí†µ ì •ë³´
    with st.sidebar:
      
        st.markdown("---")
        st.header("â„¹ï¸ ê³µí†µ ì •ë³´")

        # ê³µê°œìš© ë‚ ì§œ ë²”ìœ„ ì•ˆë‚´
        st.info(f"""
        **ğŸ“… ê³µê°œ ë°ì´í„° ë²”ìœ„**

        {PUBLIC_START_DATE.strftime('%Y-%m-%d')} ~ {PUBLIC_END_DATE.strftime('%Y-%m-%d')}

        ë°ëª¨ ì ìš© ê¸°ê°„ì…ë‹ˆë‹¤.
        """)

        st.info("""
        **ğŸ¤– LLM ëª¨ë¸**

        GPT-5 (OpenAI ìµœì‹  ëª¨ë¸)
        """)

    # ========================================================================
    # íƒ­ 1: ì¼ì¼ ë¦¬í¬íŠ¸
    # ========================================================================
    with tab_daily:
        st.header("ğŸ“… ì¼ì¼ í™œë™ ë¦¬í¬íŠ¸")
        st.markdown("---")

        # ë‚ ì§œ ì„ íƒ (íƒ­ ë‚´ë¶€)
        col1, col2 = st.columns([3, 1])
        with col1:
            default_date = PUBLIC_END_DATE
            selected_date = st.date_input(
                "ğŸ“… ë¶„ì„í•  ë‚ ì§œ",
                value=default_date,
                min_value=PUBLIC_START_DATE,
                max_value=PUBLIC_END_DATE,
                key="daily_date"
            )
            date_str = selected_date.strftime("%Y-%m-%d")

        with col2:
            st.markdown("<br>", unsafe_allow_html=True)
            if st.button("ğŸ“¥ ë°ì´í„° ë¡œë“œ", type="primary", key="daily_load"):
                st.cache_data.clear()
                st.rerun()

        # ë°ì´í„° ë¡œë“œ
        with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
            df = load_daily_data(date_str)

        if df is None:
            st.error(f"âš ï¸  {date_str}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ë‹¤ë¥¸ ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return

        weekday = get_weekday_korean(date_str)
        st.success(f"âœ… {date_str} ({weekday}) ë°ì´í„° ë¡œë“œ ì™„ë£Œ (ì´ {len(df)}ê°œ í™œë™)")

        # 2-Column Layout: ì™¼ìª½(ì‹œê°í™”), ì˜¤ë¥¸ìª½(LLM í”¼ë“œë°±)
        left_col, right_col = st.columns([2, 1])

        with left_col:

            # 1. ì „ì²´ í†µê³„
            show_statistics(df, date_str)

            st.markdown("---")

            # 2. Agency íŒŒì´ì°¨íŠ¸
            show_agency_pie_chart(df)

            st.markdown("---")

            # 3. ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            show_category_distribution(df)

            st.markdown("---")

            # 4. ìˆ˜ë©´ ë¶„ì„
            show_sleep_breakdown(df)

            st.markdown("---")

            # 5. 5ê°œ ì˜ì—­ ìƒì„¸ ë¶„ì„ (Interactive)
            show_five_areas_analysis(df)

        with right_col:
            st.header("ğŸŒ ê³µê°œ ë°°í¬ìš© LLM í”¼ë“œë°±")

            # ì¼ì¼ í”¼ë“œë°± ì˜ì—­
            show_llm_feedback(date_str)

    # ========================================================================
    # íƒ­ 2: ì£¼ê°„ ë¦¬í¬íŠ¸ (V2 Public)
    # ========================================================================
    with tab_weekly:
        st.header("ğŸ“ˆ ì£¼ê°„ í™œë™ ë¦¬í¬íŠ¸")
        st.markdown("---")
        # ë‚ ì§œ ì„ íƒ
        col_start, col_end, col_btn = st.columns([2, 2, 1])
        with col_start:
            start_date = st.date_input(
                "ì‹œì‘ì¼",
                value=PUBLIC_START_DATE,
                min_value=PUBLIC_START_DATE,
                max_value=PUBLIC_END_DATE,
                key="weekly_start"
            )
        with col_end:
            end_date = st.date_input(
                "ì¢…ë£Œì¼",
                value=min(start_date + timedelta(days=6), PUBLIC_END_DATE),
                min_value=start_date,
                max_value=PUBLIC_END_DATE,
                key="weekly_end"
            )
        with col_btn:
            st.write("")  # ê°„ê²© ì¡°ì •
            if st.button("ğŸ“¥ ë¡œë“œ", type="primary", key="weekly_load", use_container_width=True):
                st.cache_data.clear()
                st.rerun()

        start_date_str = start_date.strftime("%Y-%m-%d")
        end_date_str = end_date.strftime("%Y-%m-%d")

        # ë°ì´í„° ë¡œë“œ
        with st.spinner(f"ì£¼ê°„ ë°ì´í„° ë¡œë”© ì¤‘... ({start_date_str} ~ {end_date_str})"):
            df = load_weekly_data(start_date_str, end_date_str)

        if df is None or df.empty:
            st.error(f"âš ï¸ {start_date_str} ~ {end_date_str} ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ë‹¤ë¥¸ ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return

        st.success(f"âœ… ì£¼ê°„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {start_date_str} ~ {end_date_str} (ì´ {len(df)}ê°œ í™œë™)")

        # 2-Column Layout: ì™¼ìª½(ì‹œê°í™”/í†µê³„), ì˜¤ë¥¸ìª½(LLM í”¼ë“œë°±)
        left_col, right_col = st.columns([2, 1])

        with left_col:
            # 1. ì£¼ê°„ í†µê³„
            show_statistics(df, start_date_str, is_weekly=True, start_date=start_date_str, end_date=end_date_str)

            st.markdown("---")

            # 2. Agency íŒŒì´ì°¨íŠ¸
            show_agency_pie_chart(df)

            st.markdown("---")

            # 3. ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            show_category_distribution(df)

            st.markdown("---")

            # 4. ì¼ë³„ ìš”ì•½ (ì£¼ê°„ ì „ìš©)
            st.subheader("ğŸ“… ì¼ë³„ ìš”ì•½")
            if 'ref_date' in df.columns:
                agg_dict = {'original_id': 'count'} if 'original_id' in df.columns else {}

                # duration ì»¬ëŸ¼ ì°¾ê¸°
                if 'duration_minutes' in df.columns:
                    agg_dict['duration_minutes'] = 'sum'
                    duration_col = 'duration_minutes'
                elif 'duration_hours' in df.columns:
                    agg_dict['duration_hours'] = 'sum'
                    duration_col = 'duration_hours'
                elif 'duration' in df.columns:
                    agg_dict['duration'] = 'sum'
                    duration_col = 'duration'
                else:
                    duration_col = None

                if agg_dict:
                    daily_summary = df.groupby('ref_date').agg(agg_dict)

                    if duration_col:
                        if duration_col == 'duration_minutes' or duration_col == 'duration':
                            daily_summary['ì´ ì‹œê°„'] = daily_summary[duration_col].apply(format_duration)
                        else:  # duration_hours
                            daily_summary['ì´ ì‹œê°„'] = daily_summary[duration_col].apply(lambda x: f"{x:.1f}h")

                    if 'original_id' in daily_summary.columns:
                        daily_summary = daily_summary.rename(columns={'original_id': 'í™œë™ ìˆ˜'})

                    display_cols = []
                    if 'ì´ ì‹œê°„' in daily_summary.columns:
                        display_cols.append('ì´ ì‹œê°„')
                    if 'í™œë™ ìˆ˜' in daily_summary.columns:
                        display_cols.append('í™œë™ ìˆ˜')

                    if display_cols:
                        st.dataframe(daily_summary[display_cols], use_container_width=True)
                    else:
                        st.info("ì¼ë³„ ìš”ì•½ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ì¼ë³„ ìš”ì•½ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì¼ë³„ ìš”ì•½ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with right_col:
            st.header("ğŸŒ ê³µê°œìš© LLM í”¼ë“œë°±")
            st.caption("ğŸ¤– Powered by GPT-5 | V2 Public | ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ì¼ë°˜í™”ëœ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")

            # í”¼ë“œë°± ìƒì„±/ë¡œë“œ ë²„íŠ¼
            col1, col2 = st.columns([1, 1])

            with col1:
                load_button = st.button("ğŸ“¥ í”¼ë“œë°± ë¶ˆëŸ¬ì˜¤ê¸°", type="primary", use_container_width=True, key="weekly_load_btn")

            with col2:
                regenerate_button = st.button("ğŸ”„ ìƒˆë¡œ ìƒì„±", use_container_width=True, key="weekly_regenerate_btn")

            st.markdown("---")

            # í”¼ë“œë°± í‘œì‹œ ì˜ì—­
            if load_button or regenerate_button:
                with st.spinner("í”¼ë“œë°± ë¡œë”© ì¤‘..." if load_button else "í”¼ë“œë°± ìƒì„± ì¤‘..."):
                    if regenerate_button:
                        # ê°•ì œ ì¬ìƒì„±: ê¸°ì¡´ ê³µê°œìš© í”¼ë“œë°± ì‚­ì œ í›„ ìƒì„±
                        try:
                            existing = PublicWeeklyFeedbackDocument.find(
                                target_date=start_date_str,
                                end_date=end_date_str
                            )
                            if existing:
                                pass  # ì¼ë‹¨ ë®ì–´ì“°ê¸°ë¡œ ì²˜ë¦¬
                        except:
                            pass

                    feedback, is_new, metrics = load_or_generate_weekly_feedback(
                        start_date_str, end_date_str, df
                    )

                    if is_new:
                        st.success("âœ… ìƒˆë¡œìš´ í”¼ë“œë°±ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.info("ğŸ“¥ ì €ì¥ëœ í”¼ë“œë°±ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

                    # ë©”íŠ¸ë¦­ ë¯¸ë¦¬ë³´ê¸°
                    if metrics:
                        with st.expander("ğŸ“Š ë©”íŠ¸ë¦­ ë¯¸ë¦¬ë³´ê¸°"):
                            st.json(metrics)

                    st.markdown("---")
                    st.markdown("### ğŸ“‹ ì£¼ê°„ í”¼ë“œë°±")
                    st.markdown(feedback)
            else:
                # ì´ˆê¸° ìƒíƒœ
                st.info("""
                    **ğŸŒ GPT-5 ê¸°ë°˜ ì£¼ê°„ í”¼ë“œë°± (V2 Public)**

                **ë¶„ì„ ë²”ìœ„**:
                - ğŸ“Š ì‚¬ì „ ê³„ì‚°ëœ ë©”íŠ¸ë¦­ ê¸°ë°˜ ë¶„ì„
                - ğŸ¯ Agency ëª¨ë“œë³„ ì‹œê°„ ë°°ë¶„ ë° íŒ¨í„´
                - ğŸ”„ Drain/Recovery ë¹„ìœ¨ ë¶„ì„
                - ğŸ“ˆ ì£¼ê°„ ëŒ€í‘œ íƒœê·¸ 5-7ê°œ ì¶”ì¶œ

                **í”„ë¼ì´ë²„ì‹œ ë³´í˜¸**:
                - ê°œì¸ ì‹ë³„ ì •ë³´ ì œì™¸
                - ë¯¼ê°í•œ ë©”ëª¨ ë‚´ìš© ë¹„ê³µê°œ
                - ì¸ê°„ê´€ê³„ ìƒì„¸ ë‚´ìš© ë¹„ê³µê°œ

                **ëª¨ë¸**: GPT-5 (OpenAI ìµœì‹  ëª¨ë¸)

                ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ í”¼ë“œë°±ì„ í™•ì¸í•˜ì„¸ìš”.
                """)

                # ìë™ ë¡œë“œ ì˜µì…˜
                if st.checkbox("í˜ì´ì§€ ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ í”¼ë“œë°± ë¶ˆëŸ¬ì˜¤ê¸°", key="weekly_auto_load"):
                    feedback, is_new, metrics = load_or_generate_weekly_feedback(
                        start_date_str, end_date_str, df
                    )
                    if metrics:
                        with st.expander("ğŸ“Š ë©”íŠ¸ë¦­ ë¯¸ë¦¬ë³´ê¸°"):
                            st.json(metrics)
                    st.markdown("---")
                    st.markdown("### ğŸ“‹ ì£¼ê°„ í”¼ë“œë°±")
                    st.markdown(feedback)

    # ========================================================================
    # íƒ­ 3: ì›”ê°„ ë¦¬í¬íŠ¸ (V2 Public)
    # ========================================================================
    with tab_monthly:
        st.header("ğŸ“Š ì›”ê°„ í™œë™ ë¦¬í¬íŠ¸")
        st.markdown("---")
        # ë‚ ì§œ ì„ íƒ (ìƒ˜í”Œ ê¸°ê°„ìœ¼ë¡œ ì œí•œ)
        current_year = PUBLIC_END_DATE.year
        current_month = PUBLIC_END_DATE.month

        # ìƒ˜í”Œ ê¸°ê°„ì˜ ì—°ë„/ì›” ë²”ìœ„ ê³„ì‚°
        min_year = PUBLIC_START_DATE.year
        max_year = PUBLIC_END_DATE.year
        min_month = PUBLIC_START_DATE.month if min_year == max_year else 1
        max_month = PUBLIC_END_DATE.month if min_year == max_year else 12

        col_year, col_month, col_btn = st.columns([2, 2, 1])
        with col_year:
            year = st.number_input(
                "ì—°ë„",
                min_value=min_year,
                max_value=max_year,
                value=current_year,
                step=1,
                key="monthly_year"
            )
        with col_month:
            month = st.number_input(
                "ì›”",
                min_value=min_month,
                max_value=max_month,
                value=current_month,
                step=1,
                key="monthly_month"
            )
        with col_btn:
            st.write("")  # ê°„ê²© ì¡°ì •
            if st.button("ğŸ“¥ ë¡œë“œ", type="primary", key="monthly_load", use_container_width=True):
                st.cache_data.clear()
                st.rerun()

        # ë°ì´í„° ë¡œë“œ
        with st.spinner(f"ì›”ê°„ ë°ì´í„° ë¡œë”© ì¤‘... ({year}ë…„ {month}ì›”)"):
            df = load_monthly_data(year, month)

        if df is None or df.empty:
            st.error(f"âš ï¸ {year}ë…„ {month}ì›”ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ë‹¤ë¥¸ ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return

        st.success(f"âœ… ì›”ê°„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {year}ë…„ {month}ì›” (ì´ {len(df)}ê°œ í™œë™)")

        # 2-Column Layout: ì™¼ìª½(ì‹œê°í™”/í†µê³„), ì˜¤ë¥¸ìª½(LLM í”¼ë“œë°±)
        left_col, right_col = st.columns([2, 1])

        with left_col:
            st.subheader(f"ğŸ“Š {year}ë…„ {month}ì›” ì „ì²´ í†µê³„")

            col1, col2 = st.columns(2)
            with col1:
                # duration_minutes ì»¬ëŸ¼ ì²´í¬
                if 'duration_minutes' in df.columns:
                    st.metric("ì´ ê¸°ë¡ ì‹œê°„", format_duration(df['duration_minutes'].sum()))
                elif 'duration_hours' in df.columns:
                    st.metric("ì´ ê¸°ë¡ ì‹œê°„", f"{df['duration_hours'].sum():.1f}h")
                elif 'duration' in df.columns:
                    st.metric("ì´ ê¸°ë¡ ì‹œê°„", format_duration(df['duration'].sum()))
                else:
                    st.metric("ì´ ê¸°ë¡ ì‹œê°„", "N/A")
            with col2:
                st.metric("ì´ í™œë™ ìˆ˜", f"{len(df)}ê°œ")

            st.markdown("---")

            # Agency íŒŒì´ì°¨íŠ¸
            show_agency_pie_chart(df)

            st.markdown("---")

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            show_category_distribution(df)

            st.markdown("---")

            # ì£¼ë³„ ìš”ì•½
            st.subheader("ğŸ“… ì£¼ë³„ ìš”ì•½")
            if 'ref_date' in df.columns:
                df_copy = df.copy()
                df_copy['week'] = pd.to_datetime(df_copy['ref_date']).dt.isocalendar().week

                agg_dict = {'original_id': 'count'} if 'original_id' in df_copy.columns else {}

                # duration ì»¬ëŸ¼ ì°¾ê¸°
                if 'duration_minutes' in df_copy.columns:
                    agg_dict['duration_minutes'] = 'sum'
                    duration_col = 'duration_minutes'
                elif 'duration_hours' in df_copy.columns:
                    agg_dict['duration_hours'] = 'sum'
                    duration_col = 'duration_hours'
                elif 'duration' in df_copy.columns:
                    agg_dict['duration'] = 'sum'
                    duration_col = 'duration'
                else:
                    duration_col = None

                if agg_dict:
                    weekly_summary = df_copy.groupby('week').agg(agg_dict)

                    if duration_col:
                        if duration_col == 'duration_minutes' or duration_col == 'duration':
                            weekly_summary['ì´ ì‹œê°„'] = weekly_summary[duration_col].apply(format_duration)
                        else:  # duration_hours
                            weekly_summary['ì´ ì‹œê°„'] = weekly_summary[duration_col].apply(lambda x: f"{x:.1f}h")

                    if 'original_id' in weekly_summary.columns:
                        weekly_summary = weekly_summary.rename(columns={'original_id': 'í™œë™ ìˆ˜'})

                    display_cols = []
                    if 'ì´ ì‹œê°„' in weekly_summary.columns:
                        display_cols.append('ì´ ì‹œê°„')
                    if 'í™œë™ ìˆ˜' in weekly_summary.columns:
                        display_cols.append('í™œë™ ìˆ˜')

                    if display_cols:
                        st.dataframe(weekly_summary[display_cols], use_container_width=True)
                    else:
                        st.info("ì£¼ë³„ ìš”ì•½ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ì£¼ë³„ ìš”ì•½ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì£¼ë³„ ìš”ì•½ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with right_col:
            st.header("ğŸŒ ê³µê°œìš© LLM í”¼ë“œë°±")
            st.caption("ğŸ¤– Powered by GPT-5 | V2 Public | ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ì¼ë°˜í™”ëœ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.")

            # í”¼ë“œë°± ìƒì„±/ë¡œë“œ ë²„íŠ¼
            col1, col2 = st.columns([1, 1])

            with col1:
                load_button = st.button("ğŸ“¥ í”¼ë“œë°± ë¶ˆëŸ¬ì˜¤ê¸°", type="primary", use_container_width=True, key="monthly_load_btn")

            with col2:
                regenerate_button = st.button("ğŸ”„ ìƒˆë¡œ ìƒì„±", use_container_width=True, key="monthly_regenerate_btn")

            st.markdown("---")

            # í”¼ë“œë°± í‘œì‹œ ì˜ì—­
            if load_button or regenerate_button:
                with st.spinner("í”¼ë“œë°± ë¡œë”© ì¤‘..." if load_button else "í”¼ë“œë°± ìƒì„± ì¤‘ (ì£¼ê°„ ë¦¬í¬íŠ¸ ë³‘ë ¬ ìƒì„± í›„ ì›”ê°„ ìš”ì•½)..."):
                    if regenerate_button:
                        # ê°•ì œ ì¬ìƒì„±: ê¸°ì¡´ ê³µê°œìš© í”¼ë“œë°± ì‚­ì œ í›„ ìƒì„±
                        try:
                            existing = PublicMonthlyFeedbackDocument.find(
                                year=year,
                                month=month
                            )
                            if existing:
                                pass  # ì¼ë‹¨ ë®ì–´ì“°ê¸°ë¡œ ì²˜ë¦¬
                        except:
                            pass

                    feedback, is_new = load_or_generate_monthly_feedback(
                        year, month, df
                    )

                    if is_new:
                        st.success("âœ… ìƒˆë¡œìš´ í”¼ë“œë°±ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.info("ğŸ“¥ ì €ì¥ëœ í”¼ë“œë°±ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

                    st.markdown("---")
                    st.markdown("### ğŸ“‹ ì›”ê°„ í”¼ë“œë°±")
                    st.markdown(feedback)
            else:
                # ì´ˆê¸° ìƒíƒœ
                st.info("""
                    **ğŸŒ GPT-5 ê¸°ë°˜ ì›”ê°„ í”¼ë“œë°± (V2 Public)**

                **ë¶„ì„ ë²”ìœ„**:
                - ğŸ“Š ì£¼ê°„ V2 Public ë¦¬í¬íŠ¸ ê¸°ë°˜ ê³„ì¸µì  ìš”ì•½
                - ğŸ”„ ì›”ê°„ íŠ¸ë Œë“œ ë° ë°˜ë³µ íŒ¨í„´ ë¶„ì„
                - ğŸ¯ ì¥ê¸°ì  ì„±ê³¼ ë° ë¬¸ì œì  ì‹ë³„
                - ğŸ’¡ ë‹¤ìŒ ë‹¬ ê°œì„  ì „ëµ ì œì‹œ

                **í”„ë¼ì´ë²„ì‹œ ë³´í˜¸**:
                - ê°œì¸ ì‹ë³„ ì •ë³´ ì œì™¸
                - ë¯¼ê°í•œ ë©”ëª¨ ë‚´ìš© ë¹„ê³µê°œ
                - ì¸ê°„ê´€ê³„ ìƒì„¸ ë‚´ìš© ë¹„ê³µê°œ

                **ëª¨ë¸**: GPT-5 (OpenAI ìµœì‹  ëª¨ë¸)

                ìœ„ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ í”¼ë“œë°±ì„ í™•ì¸í•˜ì„¸ìš”.
                """)

                # ìë™ ë¡œë“œ ì˜µì…˜
                if st.checkbox("í˜ì´ì§€ ë¡œë“œ ì‹œ ìë™ìœ¼ë¡œ í”¼ë“œë°± ë¶ˆëŸ¬ì˜¤ê¸°", key="monthly_auto_load"):
                    feedback, is_new = load_or_generate_monthly_feedback(
                        year, month, df
                    )
                    st.markdown("---")
                    st.markdown("### ğŸ“‹ ì›”ê°„ í”¼ë“œë°±")
                    st.markdown(feedback)


if __name__ == "__main__":
    main()
