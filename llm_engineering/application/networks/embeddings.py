from functools import cached_property
from pathlib import Path
from typing import Optional

import numpy as np
from loguru import logger
from numpy.typing import NDArray
from sentence_transformers.SentenceTransformer import SentenceTransformer
from sentence_transformers.cross_encoder import CrossEncoder
from transformers import AutoTokenizer

from llm_engineering.settings import settings

from .base import SingletonMeta


class EmbeddingModelSingleton(metaclass=SingletonMeta):
    """
    A singleton class that provides a pre-trained transformer model for generating embeddings of input text.
    Supports both local models (SentenceTransformer) and OpenAI API.
    """

    def __init__(
        self,
        model_id: str = settings.TEXT_EMBEDDING_MODEL_ID,
        device: str = settings.RAG_MODEL_DEVICE,
        cache_dir: Optional[Path] = None,
    ) -> None:
        self._model_id = model_id
        self._device = device

        # OpenAI 모델 체크
        self._is_openai = model_id.startswith("text-embedding-")

        if self._is_openai:
            # OpenAI API 사용
            from openai import OpenAI
            self._client = OpenAI(api_key=settings.OPENAI_API_KEY)
            logger.info(f"Using OpenAI embedding model: {model_id}")
        else:
            # 로컬 SentenceTransformer 사용
            self._model = SentenceTransformer(
                self._model_id,
                device=self._device,
                cache_folder=str(cache_dir) if cache_dir else None,
            )
            self._model.eval()
            logger.info(f"Using local SentenceTransformer model: {model_id}")

    @property
    def model_id(self) -> str:
        """
        Returns the identifier of the pre-trained transformer model to use.

        Returns:
            str: The identifier of the pre-trained transformer model to use.
        """

        return self._model_id

    @cached_property
    def embedding_size(self) -> int:
        """
        Returns the size of the embeddings generated by the pre-trained transformer model.

        Returns:
            int: The size of the embeddings generated by the pre-trained transformer model.
        """
        if self._is_openai:
            # OpenAI text-embedding-3-small: 1536
            # OpenAI text-embedding-3-large: 3072
            if "small" in self._model_id:
                return 1536
            elif "large" in self._model_id:
                return 3072
            else:
                return 1536  # default
        else:
            dummy_embedding = self._model.encode("")
            return dummy_embedding.shape[0]

    @property
    def max_input_length(self) -> int:
        """
        Returns the maximum length of input text to tokenize.

        Returns:
            int: The maximum length of input text to tokenize.
        """
        if self._is_openai:
            return 8191  # OpenAI embedding models max tokens
        else:
            return self._model.max_seq_length

    @property
    def tokenizer(self) -> AutoTokenizer:
        """
        Returns the tokenizer used to tokenize input text.

        Returns:
            AutoTokenizer: The tokenizer used to tokenize input text.
        """
        if self._is_openai:
            raise NotImplementedError("Tokenizer not available for OpenAI models")
        else:
            return self._model.tokenizer

    def __call__(
        self, input_text: str | list[str], to_list: bool = True
    ) -> NDArray[np.float32] | list[float] | list[list[float]]:
        """
        Generates embeddings for the input text using the pre-trained transformer model.

        Args:
            input_text (str): The input text to generate embeddings for.
            to_list (bool): Whether to return the embeddings as a list or numpy array. Defaults to True.

        Returns:
            Union[np.ndarray, list]: The embeddings generated for the input text.
        """

        try:
            if self._is_openai:
                # OpenAI API 호출
                # 단일 문자열을 리스트로 변환
                texts = [input_text] if isinstance(input_text, str) else input_text

                response = self._client.embeddings.create(
                    input=texts,
                    model=self._model_id
                )

                # 임베딩 추출
                embeddings = [item.embedding for item in response.data]

                # 단일 문자열 입력이었으면 단일 임베딩 반환
                if isinstance(input_text, str):
                    embeddings = embeddings[0]

                if not to_list:
                    embeddings = np.array(embeddings)

                return embeddings
            else:
                # 로컬 SentenceTransformer 사용
                embeddings = self._model.encode(input_text)

                if to_list:
                    embeddings = embeddings.tolist()

                return embeddings

        except Exception as e:
            logger.error(f"Error generating embeddings for {self._model_id=} and {input_text=}: {e}")

            return [] if to_list else np.array([])


class CrossEncoderModelSingleton(metaclass=SingletonMeta):
    def __init__(
        self,
        model_id: str = settings.RERANKING_CROSS_ENCODER_MODEL_ID,
        device: str = settings.RAG_MODEL_DEVICE,
    ) -> None:
        """
        A singleton class that provides a pre-trained cross-encoder model for scoring pairs of input text.
        """

        self._model_id = model_id
        self._device = device

        self._model = CrossEncoder(
            model_name=self._model_id,
            device=self._device,
        )
        self._model.model.eval()

    def __call__(self, pairs: list[tuple[str, str]], to_list: bool = True) -> NDArray[np.float32] | list[float]:
        scores = self._model.predict(pairs)

        if to_list:
            scores = scores.tolist()

        return scores
