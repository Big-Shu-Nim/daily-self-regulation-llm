# llm_engineering/application/crawlers/dispatcher.py

from loguru import logger

from llm_engineering.domain.documents import UserDocument
from .base import BaseCrawler
from .calendar import CalendarCrawler
from .google_calendar import GoogleCalendarCrawler
from .naver import NaverCrawler
from .notion import NotionCrawler

# ì‹¤í–‰í•  í¬ë¡¤ëŸ¬ì˜ 'ì´ë¦„'ê³¼ 'í´ë˜ìŠ¤'ë¥¼ ë§¤í•‘í•˜ëŠ” ë ˆì§€ìŠ¤íŠ¸ë¦¬
CRAWLER_REGISTRY = {
    "calendar": CalendarCrawler,
    "google_calendar": GoogleCalendarCrawler,
    "naver": NaverCrawler,
    "notion": NotionCrawler,
}

class CrawlerDispatcher:
    """
    A config-driven factory for creating and running crawlers.
    """
    def dispatch(self, crawler_name: str, user_info: dict, **crawler_config):
        """
        Dynamically creates and runs a crawler based on its name and config.

        Args:
            crawler_name: The name of the crawler to run (e.g., "naver").
            user_info: Dict with user details, e.g., {"first_name": "Eddie", "last_name": "Yun"}.
            **crawler_config: Keyword arguments specific to the crawler's __init__ and extract methods.
        """
        logger.info(f"--- ğŸš€ Dispatching crawler: '{crawler_name}' ---")

        # 1. ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ ì°¾ê¸°
        crawler_class = CRAWLER_REGISTRY.get(crawler_name)
        if not crawler_class:
            logger.error(f"Crawler '{crawler_name}' not found in registry.")
            raise ValueError(f"Unknown crawler name: {crawler_name}")

        try:
            # 2. ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            logger.info(f"Getting user: {user_info}")
            user = UserDocument.get_or_create(**user_info)

            # 3. í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í•„ìš”í•œ `__init__` ì¸ìë§Œ ì „ë‹¬)
            # NaverCrawlerëŠ” `headless` ì¸ìê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ
            init_kwargs = {}
            if crawler_name == "naver" and "headless" in crawler_config:
                init_kwargs["headless"] = crawler_config.pop("headless")
            
            crawler_instance = crawler_class(**init_kwargs)
            logger.info(f"Successfully initialized {crawler_class.__name__}.")

            # 4. `extract` ë©”ì†Œë“œ ì‹¤í–‰ (userì™€ ë‚˜ë¨¸ì§€ ì„¤ì •ê°’ ì „ë‹¬)
            logger.info(f"Executing extract with config: {crawler_config}")
            crawler_instance.extract(user=user, **crawler_config)

            logger.success(f"--- âœ… Crawler '{crawler_name}' finished successfully ---")

        except Exception as e:
            logger.exception(f"An error occurred while running crawler '{crawler_name}'.")
            logger.error(f"--- âŒ Crawler '{crawler_name}' failed ---")